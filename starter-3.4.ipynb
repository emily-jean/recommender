{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do not change imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from urllib.parse import urljoin\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. MovieLens 100K Dataset: EDA via Pandas\n",
    "TODO: Read the README (https://grouplens.org/datasets/movielens/100k/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ML_100k_BASE_URL = 'http://files.grouplens.org/datasets/movielens/ml-100k/'\n",
    "\n",
    "def movielens_url(fname):\n",
    "    return urljoin(ML_100k_BASE_URL, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.1. Read Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>genre_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Action</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Children's</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Crime</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Drama</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Film-Noir</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Horror</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Musical</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Romance</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>War</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Western</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          genre  genre_id\n",
       "0       unknown         0\n",
       "1        Action         1\n",
       "2     Adventure         2\n",
       "3     Animation         3\n",
       "4    Children's         4\n",
       "5        Comedy         5\n",
       "6         Crime         6\n",
       "7   Documentary         7\n",
       "8         Drama         8\n",
       "9       Fantasy         9\n",
       "10    Film-Noir        10\n",
       "11       Horror        11\n",
       "12      Musical        12\n",
       "13      Mystery        13\n",
       "14      Romance        14\n",
       "15       Sci-Fi        15\n",
       "16     Thriller        16\n",
       "17          War        17\n",
       "18      Western        18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# names of the columns - see README, u.genre\n",
    "genre_cols = ['genre', 'genre_id']\n",
    "\n",
    "genres = pd.read_csv(movielens_url('u.genre'), sep='|', names=genre_cols)\n",
    "\n",
    "genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.2. Read Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 943 entries, 0 to 942\n",
      "Data columns (total 5 columns):\n",
      "user_id       943 non-null int64\n",
      "age           943 non-null int64\n",
      "sex           943 non-null object\n",
      "occupation    943 non-null object\n",
      "zip_code      943 non-null object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 36.9+ KB\n"
     ]
    }
   ],
   "source": [
    "user_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "\n",
    "# TODO: read users from u.user\n",
    "users = pd.read_csv(movielens_url('u.user'), sep='|', names=user_cols)\n",
    "\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.3. Read Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 24 columns):\n",
      "movie_id              100000 non-null object\n",
      "movie_title           0 non-null float64\n",
      "release_date          0 non-null float64\n",
      "video_release_date    0 non-null float64\n",
      "IMDb_URL              0 non-null float64\n",
      "unknown               0 non-null float64\n",
      "Action                0 non-null float64\n",
      "Adventure             0 non-null float64\n",
      "Animation             0 non-null float64\n",
      "Children's            0 non-null float64\n",
      "Comedy                0 non-null float64\n",
      "Crime                 0 non-null float64\n",
      "Documentary           0 non-null float64\n",
      "Drama                 0 non-null float64\n",
      "Fantasy               0 non-null float64\n",
      "Film-Noir             0 non-null float64\n",
      "Horror                0 non-null float64\n",
      "Musical               0 non-null float64\n",
      "Mystery               0 non-null float64\n",
      "Romance               0 non-null float64\n",
      "Sci-Fi                0 non-null float64\n",
      "Thriller              0 non-null float64\n",
      "War                   0 non-null float64\n",
      "Western               0 non-null float64\n",
      "dtypes: float64(23), object(1)\n",
      "memory usage: 18.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Be lazy - let the genre table tell you the last set of column names\n",
    "movie_cols = ['movie_id','movie_title','release_date','video_release_date','IMDb_URL'] + [g for g in genres.sort_values(by='genre_id')['genre']]\n",
    "\n",
    "# TODO: read movies from u.item\n",
    "movies = pd.read_csv(movielens_url('u.data'), sep='|', names=movie_cols)\n",
    "\n",
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Interesting... find the row with a null release_date!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: assign movie_id (to check/clean up ratings later)\n",
    "bad_row_id = None\n",
    "\n",
    "# drop the row (in place!)\n",
    "movies.drop(movies.loc[pd.isnull(movies.release_date)].index, inplace=True)\n",
    "\n",
    "# TODO: confirm it's gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: output a table including only the movies with null IMDB urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'the label [1357] is not in the [index]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1433\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m                     \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1435\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36merror\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1428\u001b[0m                 raise KeyError(\"the label [%s] is not in the [%s]\" %\n\u001b[0;32m-> 1429\u001b[0;31m                                (key, self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'the label [1357] is not in the [index]'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-33f80301d319>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# output all the fields of the first row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmovies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1357\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1326\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1440\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m                 \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36merror\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1427\u001b[0m                                     \"key\")\n\u001b[1;32m   1428\u001b[0m                 raise KeyError(\"the label [%s] is not in the [%s]\" %\n\u001b[0;32m-> 1429\u001b[0;31m                                (key, self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'the label [1357] is not in the [index]'"
     ]
    }
   ],
   "source": [
    "# output all the fields of the first row\n",
    "movies.loc[1357]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Try finding this movie with Google (it does exist) - what is special/different about it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: output all the fields of the second row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Try finding this movie with Google - comment on the likely name/origin of this movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: there is one movie with an unknown genre - what is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: find this movie using Google - what is special about it? what would you indicate as its genre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: there is a field of the movies dataset that has no useful values - what is it?\n",
    "bad_field = ''\n",
    "movies.drop(bad_field, 1, inplace=True)\n",
    "\n",
    "# It also turns out that the IMDB url's don't work :(\n",
    "movies.drop('IMDb_URL', 1, inplace=True)\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.4. Read Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "# TODO: read ratings from u.data\n",
    "ratings = pd.read_csv(movielens_url('u.data'), sep='|', names=movie_cols)\n",
    "\n",
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remember to drop ratings of our bad movie above\n",
    "\n",
    "# TODO: confirm they are gone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.5. Merge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = pd.merge(pd.merge(movies, ratings), users)\n",
    "lens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.6. Ask Interesting Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute sparsity = 100% * (# ratings) / ((# users) * (# movies))\n",
    "#       basically: what percentage of the full utility matrix is represented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Aggregate by movie_id, get stats on number (i.e. size) of ratings per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize the movie counts as a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Aggregate by user_id, get stats on number (i.e. size) of ratings per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize the user counts as a histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: comment on the last two stats tables/plots - what does this say in general about ratings per user/movie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Which movie has the most ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: are all ratings equally likely? output a bar chart of rating frequency overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: of the movies that have 100 or more ratings, what are the top-ten ranked movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: describe one more interesting question, and then query the result with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Extract Utility Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_id_to_index(id):\n",
    "    return id-1\n",
    "\n",
    "def user_index_to_id(idx):\n",
    "    return idx+1\n",
    "\n",
    "# Accounts for the bad movie\n",
    "def movie_id_to_index(id):\n",
    "    return id-1 if id<bad_row_id else id-2\n",
    "\n",
    "# Accounts for the bad movie\n",
    "def movie_index_to_id(idx):\n",
    "    return idx+1 if idx<(bad_row_id-1) else idx+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = ratings.user_id.unique().shape[0]\n",
    "num_movies = ratings.movie_id.unique().shape[0]\n",
    "\n",
    "utility = np.zeros((num_users, num_movies))\n",
    "\n",
    "for idx,rating in ratings.iterrows():\n",
    "    utility[user_id_to_index(rating.user_id), movie_id_to_index(rating.movie_id)] = rating.rating\n",
    "\n",
    "# should match above!\n",
    "sparsity = float(len(utility.nonzero()[0]))\n",
    "sparsity /= (utility.shape[0] * utility.shape[1])\n",
    "sparsity *= 100\n",
    "print('Sparsity: {:.2f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Evaluation via Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5]\n",
    "b = [1, 1, 4, 2, 10]\n",
    "print(\"{:.4f}\".format(mse(a, b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Show the mathematical operations that reproduce the above result\n",
    "\n",
    "$$ mse = \\ldots $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_utility(u1, u2):\n",
    "    return mse(u1[u1.nonzero()].flatten(), u2[u2.nonzero()].flatten())\n",
    "\n",
    "u1 = np.array([[2, 0, 0, 4, 4], [5, 5, 5, 3, 3], [2, 4, 2, 1, 2]])\n",
    "u2 = np.array([[3, 0, 0, 4, 4], [5, 5, 5, 3, 3], [2, 4, 2, 1, 7]])\n",
    "\n",
    "print(\"{:.4f}\".format(mse_utility(u1, u2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "1. Explain what operation is being performed. Include *why* it is appropriate in the context evaluating a recommender system, as well as performance implications.\n",
    "\n",
    "2. Show the mathematical operations that reproduce the above result\n",
    "\n",
    "$$ mse = \\ldots $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Similarity via Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement, only use primitive Python loops/operations\n",
    "#       sim = (A . B) / ( ||A|| ||B|| )\n",
    "def cosine_sim(v1, v2):\n",
    "    return 0.0\n",
    "    \n",
    "v1 = [5, 0, 3, 0, 2, 0, 0, 2, 0, 0]\n",
    "v2 = [3, 0, 2, 0, 1, 1, 0, 1, 0, 1]\n",
    "\n",
    "print(\"Cosine Similarity: {:.6f}, expected={:.6f}\".format(cosine_sim(v1, v2), cosine_similarity(np.array(v1).reshape(1, -1), np.array(v2).reshape(1, -1))[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_matrix(u, eps=1.0e-9):\n",
    "    step1 = u.dot(u.T) + eps\n",
    "    step2 = np.array([np.sqrt(np.diagonal(step1))])\n",
    "    return (step1 / step2 / step2.T)\n",
    "\n",
    "print(sim_matrix(u1))\n",
    "print(cosine_sim(u1[0], u1[1]))\n",
    "print(cosine_sim(u1[0], u1[2]))\n",
    "print(cosine_sim(u1[1], u1[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_allpairs(u):\n",
    "    n = u.shape[0]\n",
    "    sim = np.eye(n)\n",
    "    for x in itertools.combinations(range(n), 2):\n",
    "        s = cosine_sim(u[x[0]], u[x[1]])\n",
    "        sim[x[0], x[1]] = s\n",
    "        sim[x[1], x[0]] = s\n",
    "    \n",
    "    return sim\n",
    "\n",
    "print(\"MSE for U1: {:.4f}\".format(mse_utility(sim_matrix(u1), sim_allpairs(u1))))\n",
    "print(\"MSE for U2: {:.4f}\".format(mse_utility(sim_matrix(u2), sim_allpairs(u2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 sim_matrix(utility[:50,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 sim_allpairs(utility[:50,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "1. Explain what each line of sim_matrix is doing (including why eps is necessary)\n",
    "2. Explain why this approach is preferable to pairwise calls to cosine_sim (reference the previous two timeit calls; explain what each is doing and how it relates to your conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_users(u):\n",
    "    return sim_matrix(u)\n",
    "\n",
    "# TODO: use sim_matrix to return similarity between items (i.e. movies)\n",
    "def sim_items(u):\n",
    "    return None\n",
    "\n",
    "print(sim_items(u1))\n",
    "print(cosine_sim(u1[:, 0], u1[:, 1]))\n",
    "print(cosine_sim(u1[:, 0], u1[:, 2]))\n",
    "print(cosine_sim(u1[:, 0], u1[:, 3]))\n",
    "print(cosine_sim(u1[:, 0], u1[:, 4]))\n",
    "print(cosine_sim(u1[:, 1], u1[:, 2]))\n",
    "print(cosine_sim(u1[:, 1], u1[:, 3]))\n",
    "print(cosine_sim(u1[:, 1], u1[:, 4]))\n",
    "print(cosine_sim(u1[:, 2], u1[:, 3]))\n",
    "print(cosine_sim(u1[:, 2], u1[:, 4]))\n",
    "print(cosine_sim(u1[:, 3], u1[:, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. K-Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: given a slice from a similarity matrix (arr),\n",
    "#       index of \"self\" (self_idx),\n",
    "#       and k\n",
    "#       return dictionary of k most similar indexes as {idx:sim}\n",
    "#       HINT: look at np.argsort\n",
    "def top_k(arr, self_idx, k):\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_u1 = sim_items(u1)\n",
    "\n",
    "# Example via u1...\n",
    "print(sim_u1)\n",
    "print()\n",
    "\n",
    "# Top-2 w.r.t. row 0 (should be {1: 0.897, 2:0.937})\n",
    "print(sim_u1[0])\n",
    "print(top_k(sim_u1[0], 0, 2))\n",
    "print()\n",
    "\n",
    "# Top-2 w.r.t. row 1 (should be {0: 0.897, 2:0.957})\n",
    "print(sim_u1[1])\n",
    "print(top_k(sim_u1[1], 1, 2))\n",
    "print()\n",
    "\n",
    "# Top-3 w.r.t. col 1 (should be {0: 0.897, 2:0.957, 4:0.667})\n",
    "print(sim_u1[:, 1])\n",
    "print(top_k(sim_u1[:, 1], 1, 3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F. Recommend via Similar Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: given utility matrix (m_utility),\n",
    "#       similarity of users (m_sim_users),\n",
    "#       user index of interest (user_idx),\n",
    "#       item index of interest (item_idx),\n",
    "#       neighborhood size (k)\n",
    "# \n",
    "#       output the average of the similarity-weighted ratings\n",
    "#       of top-k similar users that have\n",
    "#       rated the item\n",
    "def rec_via_users(m_utility, m_sim_users, user_idx, item_idx, k):\n",
    "    return 0\n",
    "    \n",
    "print(u1)\n",
    "print()\n",
    "print(sim_users(u1))\n",
    "print()\n",
    "\n",
    "# Expected: 5\n",
    "print(rec_via_users(u1, sim_users(u1), 0, 1, 1))\n",
    "\n",
    "# Expected: 4.54 ~ (.588 * 5) + (.495 * 4) / (.588 + .495)\n",
    "print(rec_via_users(u1, sim_users(u1), 0, 1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F.1. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12345)\n",
    "\n",
    "def recs_via_users(m_utility, m_sim_users, k, test_n):\n",
    "    test = random.sample(range(m_sim_users.shape[0]), test_n)\n",
    "    true = []\n",
    "    pred = []\n",
    "    for user_idx in test:\n",
    "        for item_idx in range(m_utility.shape[1]):\n",
    "            if m_utility[user_idx][item_idx] != 0:\n",
    "                true.append(m_utility[user_idx][item_idx])\n",
    "                \n",
    "                p = round(rec_via_users(m_utility, m_sim_users, user_idx, item_idx, k))\n",
    "                if p != 0:    \n",
    "                    pred.append(p)\n",
    "                else:\n",
    "                    pred.append(1.0e-9)\n",
    "                        \n",
    "\n",
    "    return mse_utility(np.array([true], dtype=np.float64), np.array([pred], dtype=np.float64))\n",
    "    \n",
    "similarity_users = sim_users(utility)\n",
    "\n",
    "ks = []\n",
    "mses = []\n",
    "for i in range(50):\n",
    "    ks.append(i+1)\n",
    "    mses.append(recs_via_users(utility, similarity_users, i+1, 100))\n",
    "    print(\"{}/50\".format(i+1), mses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 recs_via_users(utility, similarity_users, 2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 recs_via_users(utility, similarity_users, 20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ks, mses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "1. Describe what is being done in the recs_via_users function - what is the evaluation approach? What would have been a more \"fair\" methodology?\n",
    "2. What do you notice happening as k increases?\n",
    "3. Based upon these results, what is a reasonable neighborhood size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G. Recommend via SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12345)\n",
    "\n",
    "# TODO: given a utility matrix and\n",
    "#       number of singular values to use\n",
    "# \n",
    "#       return a projected matrix\n",
    "#       based upon a limited number of dimensions\n",
    "#       U_pred = U S V^T\n",
    "# \n",
    "#       HINT: the svds function does most of the work for you\n",
    "def svd_projection(m_utility, num_dims):\n",
    "    return None\n",
    "\n",
    "def recs_via_svd(m_utility, num_dims, test_n):\n",
    "    test = random.sample(range(m_utility.shape[0]), test_n)    \n",
    "    svd_utility = svd_projection(utility, num_dims)\n",
    "    \n",
    "    true = []\n",
    "    pred = []\n",
    "    for user_idx in test:\n",
    "        for item_idx in range(m_utility.shape[1]):\n",
    "            if m_utility[user_idx][item_idx] != 0:\n",
    "                true.append(m_utility[user_idx][item_idx])\n",
    "                p = round(svd_utility[user_idx][item_idx])\n",
    "                \n",
    "                if p != 0:\n",
    "                    pred.append(p)\n",
    "                else:\n",
    "                    pred.append(1.0e-9)\n",
    "\n",
    "    return mse_utility(np.array([true], dtype=np.float64), np.array([pred], dtype=np.float64))\n",
    "    \n",
    "    \n",
    "ds = []\n",
    "mses = []\n",
    "for i in range(100):\n",
    "    ds.append(i+1)\n",
    "    mses.append(recs_via_svd(utility, i+1, 100))\n",
    "    print(\"{}/100\".format(i+1), mses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 recs_via_svd(utility, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 recs_via_svd(utility, 20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 recs_via_svd(utility, 40, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 3 recs_via_svd(utility, 80, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ds, mses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: comment on the relative speed/quality of the SVD approach as compared to the neighborhood approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H. TODO: Your Turn\n",
    "The previous sections explored some building blocks and methods of recommendation for the MovieLens dataset.\n",
    "In this section, you must extend this work:\n",
    "1. Implement a method that was not covered above (e.g. item-based neighborhood, direct matrix factorization) OR extend a method (e.g. incorporate rating bias)\n",
    "2. Evaluate your method similar to what was done above\n",
    "\n",
    "Do NOT change any code above - only add code/comment in this section (as many cells as you see fit). You are welcome to copy-paste code from above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Extra Credit\n",
    "If you so choose, create an actual recommendation engine using one of the supplied methods:\n",
    "1. Create a function that takes as input a dictionary of {movie_title:rating}, as well as a k, and your function should return the top k movies that have not been watched and have highest predicted ratings.\n",
    "2. Run the function on a few representative examples - analyze your results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
